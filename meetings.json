{
  "nextMeeting": {
    "date": "30.10.2023",
    "time": "17:00",
    "room": "E001",
    "papers": [
      {
        "title": "Scaling Laws for Neural Language Models",
        "link": "https://arxiv.org/pdf/2001.08361.pdf"
      }
    ]
  },
  "pastMeetings": [
    {
    "date": "16.10.2023",
    "time": "17:00",
    "room": "E001",
    "papers": [
      {
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "link": "https://arxiv.org/pdf/1810.04805.pdf"
      }
    ],
      "slides": ""
  },
    {
    "date": "09.10.2023",
    "time": "17:00",
    "room": "E001",
    "papers": [
      {
        "title": "LLaMA: Open and Efficient Foundation Language Models",
        "link": "https://arxiv.org/pdf/2302.13971.pdf"
      }
    ],
      "slides": "slides/05-llama-open-and-efficient-foundation-language-models.pdf"
    },
    {
    "date": "11.09.2023",
    "time": "17:00",
    "room": "?",
    "papers": [
      {
        "title": "Training language models to follow instructions with human feedback",
        "link": "https://arxiv.org/pdf/2203.02155.pdf"
      }
    ],
      "slides": "slides/04-instructgpt.pdf"
  },
    {
    "date": "04.09.2023",
    "time": "17:00",
    "room": "3045",
    "papers": [
      {
        "title": "Language Models are Unsupervised Multitask Learners",
        "link": "https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"
      },
      {
        "title": "Language Models are Few-Shot Learners",
        "link": "https://arxiv.org/pdf/2005.14165.pdf"
      }
    ],
      "slides": "slides/03-gpt_2_and_3.pdf"
  },
    {
      "date": "28.08.2023",
      "time": "17:00",
      "room": "E001",
      "papers": [
        {
          "title": "Improving Language Understanding by Generative Pre-Training",
          "link": "https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf"
        }
      ],
      "slides": "slides/02-Improving Language Understanding by Generative Pre-Training.pdf"
    },
    {
      "date": "21.08.2023",
      "time": "17:00",
      "room": "E001",
      "papers": [
        {
          "title": "Attention Is All You Need",
          "link": "https://arxiv.org/pdf/1706.03762.pdf"
        }
      ],
      "slides": "slides/01-attention_is_all_you_need.pdf"
    }
  ]
}
